{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1210ed30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from gymnasium import spaces\n",
    "from qiskit.transpiler import CouplingMap\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "\n",
    "from ai_linear_function_synthesis.env import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b305eb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_QUBITS = 5\n",
    "COUPLING_MAP = CouplingMap.from_line(NUM_QUBITS)\n",
    "BATCH_SIZE = 100\n",
    "SUCCESS_RATE_THRESHOLD = 0.8\n",
    "\n",
    "model_class = PPO\n",
    "NUM_TIME_STEPS = 5 * 10**5\n",
    "\n",
    "config = {\n",
    "    \"num_qubits\": NUM_QUBITS,\n",
    "    \"coupling_map\": COUPLING_MAP,\n",
    "    \"eval_batch_size\": BATCH_SIZE,\n",
    "    \"success_rate_threshold\": SUCCESS_RATE_THRESHOLD,\n",
    "    \"model_class\": model_class.__name__,\n",
    "    \"num_time_steps\": NUM_TIME_STEPS,\n",
    "}\n",
    "\n",
    "device_name = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device_name = \"cuda\"\n",
    "if torch.backends.mps.is_available():\n",
    "    device_name = \"mps\"\n",
    "print(f\"device_name: {device_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df4c46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCNN(BaseFeaturesExtractor):\n",
    "    \"\"\"\n",
    "    ref: stable-baselines3 documentation & https://github.com/greentfrapp/snake\n",
    "    :param observation_space: (gym.Space)\n",
    "    :param features_dim: (int) Number of features extracted.\n",
    "        This corresponds to the number of unit for the last layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, observation_space: spaces.Box, features_dim: int = 64):\n",
    "        super().__init__(observation_space, features_dim)\n",
    "        # We assume CxHxW images (channels first)\n",
    "        # Re-ordering will be done by pre-preprocessing or wrapper\n",
    "        n_input_channels = observation_space.shape[0]\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(n_input_channels, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "        # Compute shape by doing one forward pass\n",
    "        with torch.no_grad():\n",
    "            n_flatten = self.cnn(\n",
    "                torch.as_tensor(observation_space.sample()[None]).float()\n",
    "            ).shape[1]\n",
    "\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(n_flatten, features_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(features_dim, features_dim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, (nn.Linear, nn.Conv2d)):\n",
    "            torch.nn.init.xavier_uniform_(module.weight)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "\n",
    "    def forward(self, observations: torch.Tensor) -> torch.Tensor:\n",
    "        return self.linear(self.cnn(observations))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ca0897",
   "metadata": {},
   "source": [
    "## Curriculum learning + sparse reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b623307",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(\n",
    "    project=\"ai-linear-function-synthesis\",\n",
    "    name=\"run_curriculum\",\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "\n",
    "env = AILinearFunctionSynthesis(\n",
    "    coupling_map=COUPLING_MAP,\n",
    "    eval_batch_size=BATCH_SIZE,\n",
    "    success_rate_threshold=SUCCESS_RATE_THRESHOLD,\n",
    "    wandb_log=True,\n",
    ")\n",
    "\n",
    "# Initialize the model\n",
    "model = model_class(\n",
    "    policy=\"CnnPolicy\",\n",
    "    env=env,\n",
    "    verbose=1,\n",
    "    policy_kwargs=dict(\n",
    "        features_extractor_class=CustomCNN,\n",
    "        features_extractor_kwargs=dict(features_dim=64),\n",
    "    ),\n",
    "    device=device_name,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.learn(\n",
    "    total_timesteps=NUM_TIME_STEPS,\n",
    "    log_interval=10**5,\n",
    "    progress_bar=True,\n",
    ")\n",
    "\n",
    "model.save(\"saved_models/lin_func_curriculum\")\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f2324f",
   "metadata": {},
   "source": [
    "## No curriculum learning + sparse reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330760c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(\n",
    "    project=\"ai-linear-function-synthesis\",\n",
    "    name=\"run_no_curriculum\",\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "\n",
    "env = AILinearFunctionSynthesisNoCurriculumLearning(\n",
    "    coupling_map=COUPLING_MAP,\n",
    "    eval_batch_size=BATCH_SIZE,\n",
    "    wandb_log=True,\n",
    ")\n",
    "\n",
    "# Initialize the model\n",
    "model = model_class(\n",
    "    policy=\"CnnPolicy\",\n",
    "    env=env,\n",
    "    verbose=1,\n",
    "    policy_kwargs=dict(\n",
    "        features_extractor_class=CustomCNN,\n",
    "        features_extractor_kwargs=dict(features_dim=64),\n",
    "    ),\n",
    "    device=device_name,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.learn(\n",
    "    total_timesteps=NUM_TIME_STEPS,\n",
    "    log_interval=10**5,\n",
    "    progress_bar=True,\n",
    ")\n",
    "\n",
    "model.save(\"saved_models/lin_func_no_curriculum\")\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02c0978",
   "metadata": {},
   "source": [
    "## Curriculum learning + dense reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65feec29",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(\n",
    "    project=\"ai-linear-function-synthesis\",\n",
    "    name=\"run_dense\",\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "\n",
    "env = AILinearFunctionSynthesisDenseReward(\n",
    "    coupling_map=COUPLING_MAP,\n",
    "    eval_batch_size=BATCH_SIZE,\n",
    "    success_rate_threshold=SUCCESS_RATE_THRESHOLD,\n",
    "    wandb_log=True,\n",
    ")\n",
    "\n",
    "# Initialize the model\n",
    "model = model_class(\n",
    "    policy=\"CnnPolicy\",\n",
    "    env=env,\n",
    "    verbose=1,\n",
    "    policy_kwargs=dict(\n",
    "        features_extractor_class=CustomCNN,\n",
    "        features_extractor_kwargs=dict(features_dim=64),\n",
    "    ),\n",
    "    device=device_name,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.learn(\n",
    "    total_timesteps=NUM_TIME_STEPS,\n",
    "    log_interval=10**5,\n",
    "    progress_bar=True,\n",
    ")\n",
    "\n",
    "model.save(\"saved_models/lin_func_dense\")\n",
    "\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-linear-function-synthesis-s7Bf6c__",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
